// src/file-manager.js

import { createHash } from 'crypto'
import fs from 'fs/promises'
import path from 'path'
import { peerIdFromString } from '@libp2p/peer-id'

// æ–‡ä»¶ä¼ è¾“åè®®
const PROTOCOL_ID = '/p2p-file-sharing/1.0.0'
const NETWORK_PROTOCOL_ID = '/p2p-file-sharing/network-transfer/1.0.0'
const CHUNK_SIZE = 64 * 1024 // 64KB chunks

// src/file-manager.js - ä¿®æ”¹éƒ¨åˆ†

export class FileManager {
  constructor(p2pNode, dhtManager, downloadDir = './downloads') {
    this.p2pNode = p2pNode
    this.dhtManager = dhtManager
    this.downloadDir = downloadDir
    this.activeTransfers = new Map() // æ´»è·ƒçš„ä¼ è¾“
    this.fileChunks = new Map() // æ–‡ä»¶åˆ†å—ä¿¡æ¯
    this.networkTransfers = new Map() // ç½‘ç»œä¼ è¾“çŠ¶æ€
    this.downloadQueue = new Map() // ä¸‹è½½é˜Ÿåˆ—
    this.transferStats = new Map() // ä¼ è¾“ç»Ÿè®¡

    // ç½‘ç»œæ–‡ä»¶ä¸‹è½½é…ç½®
    this.networkConfig = {
      maxConcurrentDownloads: 3,
      maxProvidersPerDownload: 5,
      chunkRetryAttempts: 3,
      providerTimeout: 30000,
      downloadTimeout: 300000, // 5åˆ†é’Ÿ
      enableRedundantDownload: true,
      enableLoadBalancing: true
    }

    this.initializeProtocols()
    this.ensureDownloadDir()
  }

  async ensureDownloadDir() {
    try {
      await fs.mkdir(this.downloadDir, { recursive: true })
      // åˆ›å»ºç½‘ç»œä¸‹è½½ä¸´æ—¶ç›®å½•
      await fs.mkdir(path.join(this.downloadDir, '.tmp'), { recursive: true })
      console.log(`Download directory ensured: ${this.downloadDir}`)
    } catch (error) {
      console.error('Error creating download directory:', error)
    }
  }

  // æ–°å¢ï¼šæ›´æ–°ä¸‹è½½ç›®å½•
  async updateDownloadDirectory(newDownloadDir) {
    console.log(`Updating download directory from ${this.downloadDir} to ${newDownloadDir}`)
    this.downloadDir = newDownloadDir
    await this.ensureDownloadDir()
  }

  // æ–°å¢ï¼šè·å–å½“å‰ä¸‹è½½ç›®å½•
  getDownloadDirectory() {
    return this.downloadDir
  }

  // ä¿®æ”¹ï¼šåˆ›å»ºç½‘ç»œä¸‹è½½ä»»åŠ¡ï¼Œä½¿ç”¨å½“å‰è®¾ç½®çš„ä¸‹è½½ç›®å½•
  async createNetworkDownloadTask(fileHash, fileName, fileInfo, providers) {
    const downloadId = `net_${fileHash}_${Date.now()}`
    
    // ä½¿ç”¨å½“å‰çš„ä¸‹è½½ç›®å½•
    const downloadPath = path.join(this.downloadDir, fileName)
    const tempDir = path.join(this.downloadDir, '.tmp', downloadId)

    // ç¡®ä¿ç›®å½•å­˜åœ¨
    await fs.mkdir(tempDir, { recursive: true })

    // é€‰æ‹©æœ€ä½³æä¾›è€…
    const selectedProviders = await this.selectOptimalProviders(providers, fileHash)

    const downloadTask = {
      id: downloadId,
      fileHash,
      fileName,
      fileInfo,
      downloadPath,
      tempDir,
      providers: selectedProviders,
      totalChunks: fileInfo.chunks || 1,
      chunkSize: fileInfo.chunkSize || CHUNK_SIZE,
      completedChunks: new Set(),
      failedChunks: new Set(),
      activeChunks: new Map(),
      startTime: Date.now(),
      status: 'initializing',
      progress: 0,
      downloadedBytes: 0,
      totalBytes: fileInfo.size || 0,
      currentSpeed: 0,
      averageSpeed: 0,
      estimatedTime: 0,
      providerStats: new Map()
    }

    this.networkTransfers.set(fileHash, downloadTask)
    return downloadTask
  }

  // ä¿®æ”¹ï¼šç®€å•ç½‘ç»œä¸‹è½½ï¼Œä½¿ç”¨å½“å‰ä¸‹è½½ç›®å½•
  async executeSimpleNetworkDownload(downloadTask) {
    const { fileHash, fileName, providers } = downloadTask
    
    // ä½¿ç”¨å½“å‰çš„ä¸‹è½½ç›®å½•
    const downloadPath = path.join(this.downloadDir, fileName)

    console.log(`ğŸ“¥ Executing simple network download for ${fileName} to ${downloadPath}`)

    for (const provider of providers) {
      try {
        console.log(`ğŸ“¡ Attempting download from provider: ${provider.peerId}`)

        const fileData = await this.requestNetworkFile(provider.peerId, fileHash, fileName)
        
        if (fileData) {
          // éªŒè¯æ–‡ä»¶å“ˆå¸Œ
          const receivedHash = createHash('sha256').update(fileData).digest('hex')
          if (receivedHash !== fileHash) {
            throw new Error('File hash verification failed')
          }

          // ä¿å­˜æ–‡ä»¶åˆ°è®¾ç½®çš„ä¸‹è½½ç›®å½•
          await fs.writeFile(downloadPath, fileData)
          
          downloadTask.status = 'completed'
          downloadTask.progress = 100
          downloadTask.downloadedBytes = fileData.length

          console.log(`âœ… Simple network download completed: ${downloadPath}`)

          return {
            success: true,
            filePath: downloadPath,
            downloadTime: Date.now() - downloadTask.startTime,
            provider: provider.peerId
          }
        }

      } catch (error) {
        console.warn(`Provider ${provider.peerId} failed:`, error.message)
        continue
      }
    }

    throw new Error('All providers failed for simple download')
  }

  // ä¿®æ”¹ï¼šç»„è£…ç½‘ç»œæ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„ä¸‹è½½è·¯å¾„
  async assembleNetworkFile(downloadTask) {
    const { tempDir, fileName } = downloadTask
    
    // ä½¿ç”¨å½“å‰çš„ä¸‹è½½ç›®å½•
    const downloadPath = path.join(this.downloadDir, fileName)
    downloadTask.downloadPath = downloadPath

    console.log(`ğŸ”§ Assembling network file: ${fileName} to ${downloadPath}`)

    const outputFile = await fs.open(downloadPath, 'w')

    try {
      for (let i = 0; i < downloadTask.totalChunks; i++) {
        const chunkPath = path.join(tempDir, `chunk_${i}`)

        try {
          const chunkData = await fs.readFile(chunkPath)
          await outputFile.write(chunkData)
        } catch (error) {
          throw new Error(`Failed to read chunk ${i}: ${error.message}`)
        }
      }
    } finally {
      await outputFile.close()
    }

    // éªŒè¯æœ€ç»ˆæ–‡ä»¶å“ˆå¸Œ
    const finalFileData = await fs.readFile(downloadPath)
    const finalHash = createHash('sha256').update(finalFileData).digest('hex')
    
    if (finalHash !== downloadTask.fileHash) {
      throw new Error('Final file hash verification failed')
    }

    console.log(`âœ… Network file assembled and verified: ${downloadPath}`)
  }

  // æ–°å¢ï¼šæ£€æŸ¥ä¸‹è½½ç›®å½•æ˜¯å¦å¯å†™
  async checkDownloadDirectoryWritable() {
    try {
      const testFile = path.join(this.downloadDir, '.write-test')
      await fs.writeFile(testFile, 'test')
      await fs.unlink(testFile)
      return true
    } catch (error) {
      console.error('Download directory is not writable:', error)
      return false
    }
  }

  // æ–°å¢ï¼šè·å–ä¸‹è½½ç›®å½•ä¿¡æ¯
  async getDownloadDirectoryInfo() {
    try {
      const stats = await fs.stat(this.downloadDir)
      const isWritable = await this.checkDownloadDirectoryWritable()
      
      return {
        path: this.downloadDir,
        exists: true,
        isDirectory: stats.isDirectory(),
        isWritable,
        size: stats.size,
        modified: stats.mtime
      }
    } catch (error) {
      return {
        path: this.downloadDir,
        exists: false,
        isDirectory: false,
        isWritable: false,
        error: error.message
      }
    }
  }

  // æ–°å¢ï¼šæ¸…ç†ä¸‹è½½ç›®å½•ä¸­çš„ä¸´æ—¶æ–‡ä»¶
  async cleanupDownloadDirectory() {
    try {
      const tempDir = path.join(this.downloadDir, '.tmp')
      
      // æ¸…ç†ä¸´æ—¶ç›®å½•
      try {
        await fs.rm(tempDir, { recursive: true, force: true })
        console.log('Cleaned up temporary download files')
      } catch (error) {
        console.debug('No temporary files to clean up')
      }

      // é‡æ–°åˆ›å»ºä¸´æ—¶ç›®å½•
      await fs.mkdir(tempDir, { recursive: true })
      
      return { success: true, message: 'Download directory cleaned up' }
    } catch (error) {
      console.error('Error cleaning up download directory:', error)
      return { success: false, error: error.message }
    }
  }

  initializeProtocols() {
    // ç­‰å¾…èŠ‚ç‚¹å¯åŠ¨åå†æ³¨å†Œåè®®
    if (this.p2pNode.node) {
      this.registerProtocolHandlers()
    } else {
      setTimeout(() => {
        if (this.p2pNode.node) {
          this.registerProtocolHandlers()
        }
      }, 1000)
    }
  }

  registerProtocolHandlers() {
    try {
      // åŸæœ‰åè®®
      this.p2pNode.node.handle(PROTOCOL_ID, ({ stream, connection }) => {
        this.handleIncomingFileRequest(stream, connection)
      })

      // ç½‘ç»œä¼ è¾“åè®®
      this.p2pNode.node.handle(NETWORK_PROTOCOL_ID, ({ stream, connection }) => {
        this.handleNetworkTransferRequest(stream, connection)
      })

      console.log('âœ… Enhanced file transfer protocols registered')
    } catch (error) {
      console.error('Error registering protocol handlers:', error)
    }
  }

  // è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
  async calculateFileHash(filePath) {
    const hash = createHash('sha256')
    const data = await fs.readFile(filePath)
    hash.update(data)
    return hash.digest('hex')
  }

  // å°†æ–‡ä»¶åˆ†å‰²æˆå—
  async splitFileIntoChunks(filePath) {
    const fileData = await fs.readFile(filePath)
    const chunks = []
    const totalChunks = Math.ceil(fileData.length / CHUNK_SIZE)

    for (let i = 0; i < totalChunks; i++) {
      const start = i * CHUNK_SIZE
      const end = Math.min(start + CHUNK_SIZE, fileData.length)
      const chunk = fileData.slice(start, end)
      const chunkHash = createHash('sha256').update(chunk).digest('hex')

      chunks.push({
        index: i,
        data: chunk,
        hash: chunkHash,
        size: chunk.length
      })
    }

    return chunks
  }

  // åˆ†äº«æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆ - æ”¯æŒç½‘ç»œåˆ†äº«ï¼‰
  async shareFile(filePath) {
    try {
      const fileName = path.basename(filePath)
      const fileStats = await fs.stat(filePath)
      const fileHash = await this.calculateFileHash(filePath)

      console.log(`ğŸŒ Sharing file to network: ${fileName}`)

      // åˆ†å‰²æ–‡ä»¶ä¸ºå—
      const chunks = await this.splitFileIntoChunks(filePath)

      // å­˜å‚¨æ–‡ä»¶å—ä¿¡æ¯
      this.fileChunks.set(fileHash, {
        filePath,
        fileName,
        fileSize: fileStats.size,
        chunks,
        totalChunks: chunks.length,
        sharedAt: Date.now(),
        networkShared: true
      })

      const fileMetadata = {
        name: fileName,
        size: fileStats.size,
        hash: fileHash,
        chunks: chunks.length,
        chunkSize: CHUNK_SIZE,
        mimeType: this.getMimeType(fileName),
        networkShared: true,
        sharedAt: Date.now()
      }

      // å‘å¸ƒåˆ°ç½‘ç»œDHT
      await this.dhtManager.publishFile(fileHash, fileMetadata)
      await this.dhtManager.provideFile(fileHash)

      console.log(`âœ… File shared to network successfully: ${fileName} (${fileHash})`)
      
      return {
        success: true,
        fileHash,
        metadata: fileMetadata,
        networkShared: true
      }
    } catch (error) {
      console.error('Error sharing file to network:', error)
      return {
        success: false,
        error: error.message
      }
    }
  }

  // ç½‘ç»œæ–‡ä»¶ä¸‹è½½ï¼ˆå¢å¼ºç‰ˆï¼‰
  async downloadFile(fileHash, fileName) {
    try {
      console.log(`ğŸŒ Starting network download: ${fileName} (${fileHash})`)

      // æ£€æŸ¥æ˜¯å¦å·²åœ¨ä¸‹è½½
      if (this.networkTransfers.has(fileHash)) {
        throw new Error('File is already being downloaded')
      }

      // æŸ¥æ‰¾ç½‘ç»œæ–‡ä»¶ä¿¡æ¯å’Œæä¾›è€…
      const fileInfo = await this.dhtManager.findFile(fileHash)
      if (!fileInfo) {
        throw new Error('File not found in network')
      }

      const providers = await this.dhtManager.findProviders(fileHash)
      if (providers.length === 0) {
        throw new Error('No providers found for this file')
      }

      console.log(`ğŸ“Š Found file info and ${providers.length} providers`)

      // åˆ›å»ºç½‘ç»œä¸‹è½½ä»»åŠ¡
      const downloadTask = await this.createNetworkDownloadTask(fileHash, fileName, fileInfo, providers)
      
      // å¼€å§‹ç½‘ç»œä¸‹è½½
      const result = await this.executeNetworkDownload(downloadTask)

      if (result.success) {
        console.log(`âœ… Network download completed: ${fileName}`)
        return {
          success: true,
          filePath: result.filePath,
          source: 'network',
          providers: providers.length,
          downloadTime: result.downloadTime
        }
      } else {
        throw new Error(result.error)
      }

    } catch (error) {
      console.error('Network download failed:', error)
      this.networkTransfers.delete(fileHash)
      return {
        success: false,
        error: error.message
      }
    }
  }

  // é€‰æ‹©æœ€ä½³æä¾›è€…
  async selectOptimalProviders(providers, fileHash) {
    console.log(`ğŸ” Selecting optimal providers from ${providers.length} available`)

    const validProviders = []
    const connectedPeers = this.p2pNode.getConnectedPeers().map(p => p.toString())

    // ä¼˜å…ˆé€‰æ‹©å·²è¿æ¥çš„æä¾›è€…
    for (const provider of providers) {
      const peerId = provider.peerId || provider.id?.toString() || provider

      // è·³è¿‡è‡ªå·±
      if (peerId === this.p2pNode.node.peerId.toString()) {
        continue
      }

      // æ£€æŸ¥æä¾›è€…å¯ç”¨æ€§
      const isConnected = connectedPeers.includes(peerId)
      const isVerified = provider.verified || false

      validProviders.push({
        peerId,
        connected: isConnected,
        verified: isVerified,
        lastSeen: provider.lastSeen || Date.now(),
        priority: this.calculateProviderPriority(provider, isConnected, isVerified)
      })
    }

    // æŒ‰ä¼˜å…ˆçº§æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
    validProviders.sort((a, b) => b.priority - a.priority)
    const selectedProviders = validProviders.slice(0, this.networkConfig.maxProvidersPerDownload)

    console.log(`âœ… Selected ${selectedProviders.length} optimal providers`)
    return selectedProviders
  }

  // è®¡ç®—æä¾›è€…ä¼˜å…ˆçº§
  calculateProviderPriority(provider, isConnected, isVerified) {
    let priority = 0

    // å·²è¿æ¥çš„æä¾›è€…ä¼˜å…ˆçº§æ›´é«˜
    if (isConnected) priority += 100

    // å·²éªŒè¯çš„æä¾›è€…ä¼˜å…ˆçº§æ›´é«˜
    if (isVerified) priority += 50

    // æœ€è¿‘è§è¿‡çš„æä¾›è€…ä¼˜å…ˆçº§æ›´é«˜
    const timeSinceLastSeen = Date.now() - (provider.lastSeen || 0)
    if (timeSinceLastSeen < 300000) priority += 30 // 5åˆ†é’Ÿå†…
    else if (timeSinceLastSeen < 3600000) priority += 10 // 1å°æ—¶å†…

    return priority
  }

  // æ‰§è¡Œç½‘ç»œä¸‹è½½
  async executeNetworkDownload(downloadTask) {
    try {
      downloadTask.status = 'downloading'
      console.log(`ğŸš€ Starting network download execution for ${downloadTask.fileName}`)

      // å¦‚æœåªæœ‰ä¸€ä¸ªå—ï¼Œä½¿ç”¨ç®€å•ä¸‹è½½
      if (downloadTask.totalChunks === 1) {
        return await this.executeSimpleNetworkDownload(downloadTask)
      } else {
        return await this.executeChunkedNetworkDownload(downloadTask)
      }

    } catch (error) {
      downloadTask.status = 'failed'
      downloadTask.error = error.message
      console.error('Network download execution failed:', error)
      throw error
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await this.cleanupNetworkDownload(downloadTask)
    }
  }

  // åˆ†å—ç½‘ç»œä¸‹è½½
  async executeChunkedNetworkDownload(downloadTask) {
    const { fileHash, fileName, providers, totalChunks } = downloadTask

    console.log(`ğŸ§© Executing chunked network download for ${fileName} (${totalChunks} chunks)`)

    // åˆ›å»ºä¸‹è½½å·¥ä½œé˜Ÿåˆ—
    const chunkQueue = Array.from({ length: totalChunks }, (_, i) => i)
    const downloadPromises = []

    // å¯åŠ¨å¹¶å‘ä¸‹è½½å·¥ä½œå™¨
    const concurrency = Math.min(this.networkConfig.maxConcurrentDownloads, providers.length)
    for (let i = 0; i < concurrency; i++) {
      downloadPromises.push(this.networkChunkDownloadWorker(downloadTask, chunkQueue, providers))
    }

    // ç­‰å¾…æ‰€æœ‰å—ä¸‹è½½å®Œæˆ
    await Promise.all(downloadPromises)

    // æ£€æŸ¥ä¸‹è½½å®Œæ•´æ€§
    if (downloadTask.completedChunks.size !== totalChunks) {
      throw new Error(`Download incomplete: ${downloadTask.completedChunks.size}/${totalChunks} chunks`)
    }

    // ç»„è£…æ–‡ä»¶
    await this.assembleNetworkFile(downloadTask)

    downloadTask.status = 'completed'
    downloadTask.progress = 100

    console.log(`âœ… Chunked network download completed: ${fileName}`)

    return {
      success: true,
      filePath: downloadTask.downloadPath,
      downloadTime: Date.now() - downloadTask.startTime,
      providers: providers.length,
      chunks: totalChunks
    }
  }

  // ç½‘ç»œå—ä¸‹è½½å·¥ä½œå™¨
  async networkChunkDownloadWorker(downloadTask, chunkQueue, providers) {
    while (chunkQueue.length > 0 && downloadTask.status === 'downloading') {
      const chunkIndex = chunkQueue.shift()
      if (chunkIndex === undefined) break

      let downloadSuccess = false
      let attempts = 0

      while (!downloadSuccess && attempts < this.networkConfig.chunkRetryAttempts) {
        attempts++

        // é€‰æ‹©æä¾›è€…ï¼ˆè½®è¯¢ï¼‰
        const provider = providers[chunkIndex % providers.length]

        try {
          await this.downloadNetworkChunk(downloadTask, chunkIndex, provider)
          downloadSuccess = true
          downloadTask.completedChunks.add(chunkIndex)

          // æ›´æ–°è¿›åº¦
          this.updateNetworkDownloadProgress(downloadTask)

          console.log(`âœ… Chunk ${chunkIndex} downloaded from ${provider.peerId}`)

        } catch (error) {
          console.warn(`Failed to download chunk ${chunkIndex} from ${provider.peerId} (attempt ${attempts}):`, error.message)

          if (attempts >= this.networkConfig.chunkRetryAttempts) {
            downloadTask.failedChunks.add(chunkIndex)
            // é‡æ–°æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œå°è¯•å…¶ä»–æä¾›è€…
            if (providers.length > 1) {
              chunkQueue.push(chunkIndex)
            }
          }

          // ç­‰å¾…é‡è¯•
          await new Promise(resolve => setTimeout(resolve, 1000 * attempts))
        }
      }
    }
  }

  // ä¸‹è½½ç½‘ç»œå—
  async downloadNetworkChunk(downloadTask, chunkIndex, provider) {
    const chunkPath = path.join(downloadTask.tempDir, `chunk_${chunkIndex}`)

    // æ£€æŸ¥å—æ˜¯å¦å·²å­˜åœ¨
    try {
      await fs.access(chunkPath)
      return // å—å·²å­˜åœ¨
    } catch {
      // å—ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½
    }

    console.log(`ğŸ“¦ Downloading chunk ${chunkIndex} from ${provider.peerId}`)

    const chunk = await this.requestNetworkChunk(provider.peerId, downloadTask.fileHash, chunkIndex)

    if (!chunk || !chunk.data) {
      throw new Error(`No chunk data received for chunk ${chunkIndex}`)
    }

    // éªŒè¯å—å“ˆå¸Œï¼ˆå¦‚æœæä¾›ï¼‰
    if (chunk.hash) {
      const receivedHash = createHash('sha256').update(chunk.data).digest('hex')
      if (receivedHash !== chunk.hash) {
        throw new Error(`Chunk ${chunkIndex} hash verification failed`)
      }
    }

    // ä¿å­˜å—
    await fs.writeFile(chunkPath, chunk.data)
    downloadTask.downloadedBytes += chunk.data.length

    // æ›´æ–°æä¾›è€…ç»Ÿè®¡
    if (!downloadTask.providerStats.has(provider.peerId)) {
      downloadTask.providerStats.set(provider.peerId, { chunks: 0, bytes: 0, errors: 0 })
    }
    const stats = downloadTask.providerStats.get(provider.peerId)
    stats.chunks++
    stats.bytes += chunk.data.length
  }

  // è¯·æ±‚ç½‘ç»œæ–‡ä»¶
  async requestNetworkFile(peerId, fileHash, fileName) {
    try {
      console.log(`ğŸ“¡ Requesting complete file ${fileName} from ${peerId}`)

      const peerIdObj = peerIdFromString(peerId)
      const stream = await this.p2pNode.node.dialProtocol(peerIdObj, NETWORK_PROTOCOL_ID)

      const request = {
        type: 'NETWORK_FILE_REQUEST',
        fileHash,
        fileName,
        requestId: this.generateRequestId(),
        timestamp: Date.now()
      }

      await this.sendMessage(stream, request)
      const response = await this.receiveMessage(stream)

      if (response.success && response.fileData) {
        console.log(`âœ… Received complete file data from ${peerId}`)
        return Buffer.from(response.fileData, 'base64')
      } else {
        throw new Error(response.error || 'No file data received')
      }

    } catch (error) {
      console.error(`Failed to request file from ${peerId}:`, error.message)
      throw error
    }
  }

  // è¯·æ±‚ç½‘ç»œå—
  async requestNetworkChunk(peerId, fileHash, chunkIndex) {
    try {
      console.log(`ğŸ“¦ Requesting chunk ${chunkIndex} from ${peerId}`)

      const peerIdObj = peerIdFromString(peerId)
      const stream = await this.p2pNode.node.dialProtocol(peerIdObj, NETWORK_PROTOCOL_ID)

      const request = {
        type: 'NETWORK_CHUNK_REQUEST',
        fileHash,
        chunkIndex,
        requestId: this.generateRequestId(),
        timestamp: Date.now()
      }

      await this.sendMessage(stream, request)
      const response = await this.receiveMessage(stream)

      if (response.success && response.chunkData) {
        return {
          index: chunkIndex,
          data: Buffer.from(response.chunkData, 'base64'),
          hash: response.chunkHash
        }
      } else {
        throw new Error(response.error || 'No chunk data received')
      }

    } catch (error) {
      console.error(`Failed to request chunk ${chunkIndex} from ${peerId}:`, error.message)
      throw error
    }
  }

  // å¤„ç†ç½‘ç»œä¼ è¾“è¯·æ±‚
  async handleNetworkTransferRequest(stream, connection) {
    try {
      const request = await this.receiveMessage(stream)
      const peerId = connection.remotePeer.toString()

      console.log(`ğŸ“¡ Received network transfer request from ${peerId}:`, request.type)

      let response = { success: false }

      switch (request.type) {
        case 'NETWORK_FILE_REQUEST':
          response = await this.handleNetworkFileRequest(request, peerId)
          break
        case 'NETWORK_CHUNK_REQUEST':
          response = await this.handleNetworkChunkRequest(request, peerId)
          break
        default:
          response = { success: false, error: 'Unknown request type' }
      }

      await this.sendMessage(stream, response)

    } catch (error) {
      console.error('Error handling network transfer request:', error)
      await this.sendMessage(stream, { success: false, error: error.message })
    }
  }

  // å¤„ç†ç½‘ç»œæ–‡ä»¶è¯·æ±‚
  async handleNetworkFileRequest(request, peerId) {
    try {
      const { fileHash, fileName } = request

      console.log(`ğŸ“¤ Handling file request for ${fileName} from ${peerId}`)

      const fileInfo = this.fileChunks.get(fileHash)
      if (!fileInfo) {
        return { success: false, error: 'File not found' }
      }

      // è¯»å–å®Œæ•´æ–‡ä»¶
      const fileData = await fs.readFile(fileInfo.filePath)
      
      const response = {
        success: true,
        fileData: fileData.toString('base64'),
        fileSize: fileData.length,
        fileName: fileInfo.fileName,
        provider: this.p2pNode.node.peerId.toString()
      }

      console.log(`âœ… Sent complete file ${fileName} to ${peerId}`)
      return response

    } catch (error) {
      console.error('Error handling network file request:', error)
      return { success: false, error: error.message }
    }
  }

  // å¤„ç†ç½‘ç»œå—è¯·æ±‚
  async handleNetworkChunkRequest(request, peerId) {
    try {
      const { fileHash, chunkIndex } = request

      console.log(`ğŸ“¦ Handling chunk request ${chunkIndex} from ${peerId}`)

      const fileInfo = this.fileChunks.get(fileHash)
      if (!fileInfo) {
        return { success: false, error: 'File not found' }
      }

      const chunk = fileInfo.chunks[chunkIndex]
      if (!chunk) {
        return { success: false, error: 'Chunk not found' }
      }

      const response = {
        success: true,
        chunkData: chunk.data.toString('base64'),
        chunkHash: chunk.hash,
        chunkIndex: chunkIndex,
        chunkSize: chunk.size,
        provider: this.p2pNode.node.peerId.toString()
      }

      console.log(`âœ… Sent chunk ${chunkIndex} to ${peerId}`)
      return response

    } catch (error) {
      console.error('Error handling network chunk request:', error)
      return { success: false, error: error.message }
    }
  }

  // æ›´æ–°ç½‘ç»œä¸‹è½½è¿›åº¦
  updateNetworkDownloadProgress(downloadTask) {
    const completedCount = downloadTask.completedChunks.size
    const totalCount = downloadTask.totalChunks
    const progress = (completedCount / totalCount) * 100

    downloadTask.progress = Math.round(progress * 100) / 100

    // è®¡ç®—é€Ÿåº¦
    const elapsedTime = (Date.now() - downloadTask.startTime) / 1000
    if (elapsedTime > 0) {
      downloadTask.currentSpeed = downloadTask.downloadedBytes / elapsedTime
      
      if (downloadTask.currentSpeed > 0) {
        const remainingBytes = downloadTask.totalBytes - downloadTask.downloadedBytes
        downloadTask.estimatedTime = Math.round(remainingBytes / downloadTask.currentSpeed)
      }
    }
  }

  // æ¸…ç†ç½‘ç»œä¸‹è½½
  async cleanupNetworkDownload(downloadTask) {
    try {
      if (downloadTask.tempDir) {
        await fs.rm(downloadTask.tempDir, { recursive: true, force: true })
        console.log(`ğŸ§¹ Cleaned up temp directory: ${downloadTask.tempDir}`)
      }
    } catch (error) {
      console.error('Error cleaning up network download:', error)
    }
  }

  // å¤„ç†ä¼ å…¥çš„æ–‡ä»¶è¯·æ±‚ï¼ˆåŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼‰
  async handleIncomingFileRequest(stream, connection) {
    try {
      let requestData = []
      let expectedLength = null
      let receivedLength = 0

      for await (const chunk of stream.source) {
        requestData.push(chunk)
        receivedLength += chunk.length

        // è¯»å–æ¶ˆæ¯é•¿åº¦
        if (expectedLength === null && receivedLength >= 4) {
          const allData = Buffer.concat(requestData)
          expectedLength = allData.readUInt32BE(0)
          requestData = [allData.slice(4)]
          receivedLength -= 4
        }

        // å¤„ç†å®Œæ•´çš„è¯·æ±‚
        if (expectedLength !== null && receivedLength >= expectedLength) {
          const requestBuffer = Buffer.concat(requestData).slice(0, expectedLength)
          const request = JSON.parse(requestBuffer.toString())

          await this.processFileRequest(request, stream)
          break
        }
      }
    } catch (error) {
      console.error('Error handling file request:', error)
      const errorResponse = { success: false, error: error.message }
      await this.sendResponse(stream, errorResponse)
    }
  }

  // å¤„ç†æ–‡ä»¶è¯·æ±‚ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
  async processFileRequest(request, stream) {
    try {
      if (request.type === 'CHUNK_REQUEST') {
        const { fileHash, chunkIndex } = request

        const fileInfo = this.fileChunks.get(fileHash)
        if (!fileInfo) {
          const errorResponse = { success: false, error: 'File not found' }
          await this.sendResponse(stream, errorResponse)
          return
        }

        const chunk = fileInfo.chunks[chunkIndex]
        if (!chunk) {
          const errorResponse = { success: false, error: 'Chunk not found' }
          await this.sendResponse(stream, errorResponse)
          return
        }

        const response = {
          success: true,
          data: chunk.data.toString('base64'),
          hash: chunk.hash,
          index: chunkIndex
        }

        await this.sendResponse(stream, response)
      }
    } catch (error) {
      console.error('Error processing file request:', error)
      const errorResponse = { success: false, error: error.message }
      await this.sendResponse(stream, errorResponse)
    }
  }

  // å‘é€å“åº”
  async sendResponse(stream, response) {
    const responseData = JSON.stringify(response)
    const responseBuffer = Buffer.from(responseData)

    const lengthBuffer = Buffer.allocUnsafe(4)
    lengthBuffer.writeUInt32BE(responseBuffer.length, 0)

    stream.sink(async function* () {
      yield lengthBuffer
      yield responseBuffer
    }())
  }

  // å‘é€æ¶ˆæ¯
  async sendMessage(stream, message) {
    const messageData = JSON.stringify(message)
    const messageBuffer = Buffer.from(messageData)
    const lengthBuffer = Buffer.allocUnsafe(4)
    lengthBuffer.writeUInt32BE(messageBuffer.length, 0)

    await stream.sink(async function* () {
      yield lengthBuffer
      yield messageBuffer
    }())
  }

  // æ¥æ”¶æ¶ˆæ¯
  async receiveMessage(stream) {
    let responseData = []
    let expectedLength = null
    let receivedLength = 0

    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('Message receive timeout'))
      }, this.networkConfig.providerTimeout)

      const processData = async () => {
        try {
          for await (const chunk of stream.source) {
            let buffer
            if (Buffer.isBuffer(chunk)) {
              buffer = chunk
            } else if (chunk instanceof Uint8Array) {
              buffer = Buffer.from(chunk)
            } else if (chunk && typeof chunk.subarray === 'function') {
              buffer = Buffer.from(chunk.subarray())
            } else {
              buffer = Buffer.from(new Uint8Array(chunk))
            }

            responseData.push(buffer)
            receivedLength += buffer.length

            if (expectedLength === null && receivedLength >= 4) {
              const allData = Buffer.concat(responseData)
              expectedLength = allData.readUInt32BE(0)
              responseData = [allData.slice(4)]
              receivedLength -= 4
            }

            if (expectedLength !== null && receivedLength >= expectedLength) {
              clearTimeout(timeout)
              const responseBuffer = Buffer.concat(responseData).slice(0, expectedLength)
              const response = JSON.parse(responseBuffer.toString())
              resolve(response)
              break
            }
          }
        } catch (error) {
          clearTimeout(timeout)
          reject(error)
        }
      }

      processData()
    })
  }

  // éªŒè¯å—
  verifyChunk(chunk) {
    const calculatedHash = createHash('sha256').update(chunk.data).digest('hex')
    return calculatedHash === chunk.hash
  }

  // è·å–MIMEç±»å‹
  getMimeType(fileName) {
    const ext = path.extname(fileName).toLowerCase()
    const mimeTypes = {
      '.txt': 'text/plain',
      '.pdf': 'application/pdf',
      '.jpg': 'image/jpeg',
      '.jpeg': 'image/jpeg',
      '.png': 'image/png',
      '.gif': 'image/gif',
      '.mp4': 'video/mp4',
      '.mp3': 'audio/mpeg',
      '.zip': 'application/zip',
      '.json': 'application/json',
      '.html': 'text/html',
      '.css': 'text/css',
      '.js': 'application/javascript'
    }
    return mimeTypes[ext] || 'application/octet-stream'
  }

  // è·å–ç½‘ç»œä¼ è¾“çŠ¶æ€
  getNetworkTransferStatus(fileHash) {
    const transfer = this.networkTransfers.get(fileHash)
    if (!transfer) return null

    return {
      id: transfer.id,
      fileName: transfer.fileName,
      fileHash: transfer.fileHash,
      progress: transfer.progress,
      status: transfer.status,
      downloadedChunks: transfer.completedChunks.size,
      totalChunks: transfer.totalChunks,
      downloadedBytes: transfer.downloadedBytes,
      totalBytes: transfer.totalBytes,
      currentSpeed: transfer.currentSpeed,
      averageSpeed: transfer.averageSpeed,
      estimatedTime: transfer.estimatedTime,
      elapsedTime: Date.now() - transfer.startTime,
      providers: transfer.providers.length,
      providerStats: Object.fromEntries(transfer.providerStats)
    }
  }

  // è·å–æ‰€æœ‰æ´»è·ƒä¼ è¾“ï¼ˆåŒ…æ‹¬ç½‘ç»œä¼ è¾“ï¼‰
  getActiveTransfers() {
    const transfers = []

    // åŸæœ‰ä¼ è¾“
    for (const [fileHash, transfer] of this.activeTransfers) {
      transfers.push({
        fileHash,
        type: 'local',
        ...this.getTransferStatus(fileHash)
      })
    }

    // ç½‘ç»œä¼ è¾“
    for (const [fileHash, transfer] of this.networkTransfers) {
      transfers.push({
        fileHash,
        type: 'network',
        ...this.getNetworkTransferStatus(fileHash)
      })
    }

    return transfers
  }

  // è·å–ä¼ è¾“çŠ¶æ€ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
  getTransferStatus(fileHash) {
    const transfer = this.activeTransfers.get(fileHash)
    if (!transfer) return null

    return {
      fileName: transfer.fileName,
      progress: (transfer.downloadedChunks / transfer.totalChunks) * 100,
      downloadedChunks: transfer.downloadedChunks,
      totalChunks: transfer.totalChunks,
      elapsedTime: Date.now() - transfer.startTime
    }
  }

  // è·å–ç½‘ç»œæ–‡ä»¶ç»Ÿè®¡
  getNetworkFileStats() {
    return {
      sharedFiles: this.fileChunks.size,
      activeNetworkTransfers: this.networkTransfers.size,
      totalNetworkDownloads: this.transferStats.size,
      networkProtocolsActive: true
    }
  }

  // ç”Ÿæˆè¯·æ±‚ID
  generateRequestId() {
    return `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  // æ¸…ç†èµ„æº
  destroy() {
    // æ¸…ç†æ´»è·ƒä¼ è¾“
    this.activeTransfers.clear()
    this.networkTransfers.clear()
    this.fileChunks.clear()
    this.downloadQueue.clear()
    this.transferStats.clear()

    console.log('ğŸ§¹ Enhanced File Manager destroyed')
  }
}